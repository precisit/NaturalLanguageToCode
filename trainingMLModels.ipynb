{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import nltk\n",
    "from keras import Input, regularizers\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from pygments.lexers import go\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "from tensorflow import keras\n",
    "from nltk.corpus import treebank\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#import random\n",
    "#print(random.choice(sentences)) #Print example sentence structure\n",
    "\n",
    "\n",
    "#================================================================================================#\n",
    "#========================Proccesing the data for the models======================================#\n",
    "\n",
    "nltk.download('treebank')\n",
    "sentences = treebank.tagged_sents(tagset='universal')\n",
    "sentences = sentences[:len(sentences)//8] #Using only part of treebank\n",
    "tags = set([\n",
    "    tag for sentence in treebank.tagged_sents()\n",
    "    for _, tag in sentence\n",
    "])\n",
    "print('nb_tags: %sntags: %s' % (len(tags), tags)) #number of tags we got\n",
    "print(len(sentences))\n",
    "\n",
    "\n",
    "train_test_cutoff = int(.80 * len(sentences))\n",
    "training_sentences = sentences[:train_test_cutoff]\n",
    "testing_sentences = sentences[train_test_cutoff:]\n",
    "train_val_cutoff = int(.25 * len(training_sentences))\n",
    "validation_sentences = training_sentences[:train_val_cutoff]\n",
    "training_sentences = training_sentences[train_val_cutoff:]\n",
    "\n",
    "#These properties could include information about\n",
    "# previous and next words as well as prefixes and suffixes.\n",
    "def add_basic_features(sentence_terms, index):\n",
    "    \"\"\" Compute some very basic word features.\n",
    "        :param sentence_terms: [w1, w2, ...]\n",
    "        :type sentence_terms: list\n",
    "        :param index: the index of the word\n",
    "        :type index: int\n",
    "        :return: dict containing features\n",
    "        :rtype: dict\n",
    "    \"\"\"\n",
    "    term = sentence_terms[index]\n",
    "    return {\n",
    "        'nb_terms': len(sentence_terms),\n",
    "        'term': term,\n",
    "        'is_first': index == 0,\n",
    "        'is_last': index == len(sentence_terms) - 1,\n",
    "        'is_capitalized': term[0].upper() == term[0],\n",
    "        'is_all_caps': term.upper() == term,\n",
    "        'is_all_lower': term.lower() == term,\n",
    "        'prefix-1': term[0],\n",
    "        'prefix-2': term[:2],\n",
    "        'prefix-3': term[:3],\n",
    "        'suffix-1': term[-1],\n",
    "        'suffix-2': term[-2:],\n",
    "        'suffix-3': term[-3:],\n",
    "        'prev_word': '' if index == 0 else sentence_terms[index - 1],\n",
    "        'next_word': '' if index == len(sentence_terms) - 1 else sentence_terms[index + 1]\n",
    "    }\n",
    "\n",
    "def untag(tagged_sentence):\n",
    "    \"\"\"\n",
    "    Remove the tag for each tagged term.\n",
    "    :param tagged_sentence: a POS tagged sentence\n",
    "    :type tagged_sentence: list\n",
    "    :return: a list of tags\n",
    "    :rtype: list of strings\n",
    "    \"\"\"\n",
    "    return [w for w, _ in tagged_sentence]\n",
    "\n",
    "def transform_to_dataset(tagged_sentences):\n",
    "    \"\"\"\n",
    "    Split tagged sentences to X and y datasets and append some basic features.\n",
    "    :param tagged_sentences: a list of POS tagged sentences\n",
    "    :param tagged_sentences: list of list of tuples (term_i, tag_i)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for pos_tags in tagged_sentences:\n",
    "            for index, (term, class_) in enumerate(pos_tags):\n",
    "                X.append(add_basic_features(untag(pos_tags), index))\n",
    "                y.append(class_)\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = transform_to_dataset(training_sentences)\n",
    "X_test, y_test = transform_to_dataset(testing_sentences)\n",
    "X_val, y_val = transform_to_dataset(validation_sentences)\n",
    "\n",
    "#Our neural network takes vectors as inputs, so we need to convert our dict features to vectors.\n",
    "# Fit our DictVectorizer with our set of features\n",
    "dict_vectorizer = DictVectorizer(sparse=False)\n",
    "dict_vectorizer.fit(X_train + X_test + X_val)\n",
    "# Convert dict features to vectors\n",
    "preX_train = X_train\n",
    "X_train = dict_vectorizer.transform(X_train)\n",
    "X_test = dict_vectorizer.transform(X_test)\n",
    "X_val = dict_vectorizer.transform(X_val)\n",
    "\n",
    "# Fit LabelEncoder with our list of classes\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train + y_test + y_val)\n",
    "# Encode class values as integers\n",
    "prey_train = y_train\n",
    "y_train = label_encoder.transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "y_val = label_encoder.transform(y_val)\n",
    "\n",
    "# Convert integers to dummy variables (one hot encoded)\n",
    "from keras.utils import np_utils\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "y_val = np_utils.to_categorical(y_val)\n",
    "\n",
    "def untagger(tagged_sentences):\n",
    "    X = []\n",
    "    for pos_tags in tagged_sentences:\n",
    "                X.append(untag(pos_tags))\n",
    "    return X\n",
    "simple_train_sentences = untagger(training_sentences)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#================================================================================================#\n",
    "#========================Building a model======================================#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "def build_model(input_dim, hidden_neurons, output_dim):\n",
    "    model = Sequential([\n",
    "        Dense(hidden_neurons, input_dim=input_dim),\n",
    "        Activation('relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(hidden_neurons),\n",
    "        Activation('relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(output_dim, activation='softmax')\n",
    "    ])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model_params = {\n",
    "    'build_fn': build_model,\n",
    "    'input_dim': X_train.shape[1],\n",
    "    'hidden_neurons': 512,\n",
    "    'output_dim': y_train.shape[1],\n",
    "    'epochs': 5,\n",
    "    'batch_size': 256,\n",
    "    'verbose': 1,\n",
    "    'validation_data': (X_val, y_val),\n",
    "    'shuffle': True\n",
    "}\n",
    "\n",
    "clf = KerasClassifier(**model_params)\n",
    "hist = clf.fit(X_train, y_train) #trains it\n",
    "clf.model.save('keras_mlp.h5') #Save trained model to keras_mlp.h5\n",
    "y_pred = clf.model.predict(X_test, verbose=1).argmax(-1)\n",
    "y_true = y_test.argmax(-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#================================================================================================#\n",
    "#========================Building a LSTM model======================================#\n",
    "#https://medium.com/@sabber/classifying-yelp-review-comments-using-cnn-lstm-and-visualize-word-embeddings-part-2-ca137a42a97d"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D, Conv1D\n",
    "from keras.layers import Dense, Dropout, Activation, LSTM\n",
    "class AttentionLayer(object):\n",
    "    pass\n",
    "def create_conv_model():\n",
    "    model_conv = Sequential()\n",
    "    model_conv.add(Embedding(X_train.shape[1], 100, input_length=13288))\n",
    "    model_conv.add(Dropout(0.2))\n",
    "    model_conv.add(Conv1D(64, 5, activation='relu'))\n",
    "    model_conv.add(MaxPooling1D(pool_size=4))\n",
    "    model_conv.add(AttentionLayer())\n",
    "    model_conv.add(LSTM(100))\n",
    "    model_conv.add(Dense(12, activation='sigmoid'))\n",
    "    model_conv.compile(loss='binary_crossentropy', optimizer='adam',    metrics=['accuracy'])\n",
    "    return model_conv\n",
    "\n",
    "model_conv = create_conv_model()\n",
    "model_conv.fit(X_train, y_train, validation_split=0.4, epochs = 2)\n",
    "model_conv.model.save('lstm.h5') #Save trained model to keras_mlp.h5\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#================================================================================================#\n",
    "#========================Building a CNN model======================================#\n",
    "#https://www.kaggle.com/hamishdickson/cnn-for-sentence-classification-by-yoon-kim/data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# lets import some stuff\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "num_filters = 100\n",
    "embedding_dim = 200\n",
    "sequence_length = 46\n",
    "\n",
    "inputs_2 = Input(shape=(X_train.shape[1],), dtype='int32')\n",
    "\n",
    "#Version 1: val_loss 0.26, val_acc 0.91\n",
    "\n",
    "def create_cnn_model():\n",
    "    model_cnn = Sequential()\n",
    "    model_cnn.add(Embedding(X_train.shape[1], 100, input_length=13288))\n",
    "    model_cnn.add(Conv1D(num_filters, kernel_size= 3, activation='relu', kernel_regularizer=regularizers.l2(3)))\n",
    "    #model_cnn.add(Conv1D(num_filters, kernel_size=(4), activation='relu', kernel_regularizer=regularizers.l2(3)))\n",
    "    #model_cnn.add(Conv1D(num_filters, kernel_size=(5), activation='relu', kernel_regularizer=regularizers.l2(3)))\n",
    "    model_cnn.add(MaxPooling1D())\n",
    "    #model_cnn.add(MaxPooling1D(pool_size=4))\n",
    "    #model_cnn.add(MaxPooling1D(pool_size=5))\n",
    "    model_cnn.add(Flatten())\n",
    "    model_cnn.add(Dropout(0.2))\n",
    "    model_cnn.add(Dense(12, activation='softmax')) #Or sigmoid\n",
    "    model_cnn.compile(loss='binary_crossentropy', optimizer='adam',    metrics=['accuracy'])\n",
    "    return model_cnn\n",
    "\n",
    "model_cnn = create_cnn_model()\n",
    "print(model_cnn.summary())\n",
    "hist_2 = model_cnn.fit(X_train, y_train, validation_split=0.4, epochs = 2, batch_size=10)\n",
    "model_cnn.model.save('cnn.h5') #Save trained model to keras_mlp.h5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(hist_2.history['accuracy'])\n",
    "plt.plot(hist_2.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist_2.history['loss'])\n",
    "plt.plot(hist_2.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#================================================================================================#\n",
    "#========================Building a RF model======================================#\n",
    "#https://blog.goodaudience.com/introduction-to-random-forest-algorithm-with-python-9efd1d8f0157"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#vectorizer = CountVectorizer(min_df=1)\n",
    "#X = vectorizer.fit_transform(preX_train).toarray()\n",
    "\n",
    "RF_model = RandomForestClassifier(n_estimators = 20)\n",
    "histRF = RF_model.fit(X_train, y_train)\n",
    "RF_predictions = RF_model.predict(X_test)\n",
    "score = accuracy_score(y_test ,RF_predictions)\n",
    "print(score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#================================================================================================#\n",
    "#========================Playing with hyperparameters with random search======================================#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "maxlen = 100\n",
    "epochs = 3\n",
    "vocab_size = len(dict_vectorizer.get_feature_names()) + 1\n",
    "X_padtrain = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_padtest = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "output_file = 'data/output.txt'\n",
    "\n",
    "# Parameter grid for grid search\n",
    "param_grid = dict(num_filters=[32, 64, 128],\n",
    "                      kernel_size=[3, 5, 7],\n",
    "                      vocab_size=[vocab_size],\n",
    "                      embedding_dim=[embedding_dim],\n",
    "                      maxlen=[maxlen])\n",
    "model = KerasClassifier(build_fn=create_cnn_model,epochs=epochs, batch_size=10,verbose=False)\n",
    "grid = RandomizedSearchCV(estimator=model, param_distributions=param_grid,cv=4, verbose=1, n_iter=5)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate testing set\n",
    "test_accuracy = grid.score(X_test, y_test)\n",
    "\n",
    "# Save and evaluate results\n",
    "with open(output_file, 'a') as f:\n",
    "    s = ('Running {} data set\\nBest Accuracy : '\n",
    "             '{:.4f}\\n{}\\nTest Accuracy : {:.4f}\\n\\n')\n",
    "    output_string = s.format(grid_result.best_score_, grid_result.best_params_, test_accuracy)\n",
    "    print(output_string)\n",
    "    f.write(output_string)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#================================================================================================#\n",
    "#========================Visulize the result======================================#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_model_performance(train_loss, train_acc, train_val_loss, train_val_acc):\n",
    "    \"\"\" Plot model loss and accuracy through epochs. \"\"\"\n",
    "    blue= '#34495E'\n",
    "    green = '#2ECC71'\n",
    "    orange = '#E23B13'\n",
    "    # plot model loss\n",
    "    fig, (ax1, ax2) = plt.subplots(2, figsize=(10, 8))\n",
    "    ax1.plot(range(1, len(train_loss) + 1), train_loss, blue, linewidth=5, label='training')\n",
    "    ax1.plot(range(1, len(train_val_loss) + 1), train_val_loss, green, linewidth=5, label='validation')\n",
    "    ax1.set_xlabel('# epoch')\n",
    "    ax1.set_ylabel('loss')\n",
    "    ax1.tick_params('y')\n",
    "    ax1.legend(loc='upper right', shadow=False)\n",
    "    ax1.set_title('Model loss through #epochs', color=orange, fontweight='bold')\n",
    "    # plot model accuracy\n",
    "    ax2.plot(range(1, len(train_acc) + 1), train_acc, blue, linewidth=5, label='training')\n",
    "    ax2.plot(range(1, len(train_val_acc) + 1), train_val_acc, green, linewidth=5, label='validation')\n",
    "    ax2.set_xlabel('# epoch')\n",
    "    ax2.set_ylabel('accuracy')\n",
    "    ax2.tick_params('y')\n",
    "    ax2.legend(loc='lower right', shadow=False)\n",
    "    ax2.set_title('Model accuracy through #epochs', color=orange, fontweight='bold')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_model_performance(\n",
    "        train_loss=histRF.history.get('loss', []),\n",
    "        train_acc=histRF.history.get('accuracy', []),\n",
    "        train_val_loss=histRF.history.get('val_loss', []),\n",
    "        train_val_acc=histRF.history.get('val_accuracy', [])\n",
    "    )\n",
    "score = accuracy_score(y_test ,RF_predictions)\n",
    "print(score)\n",
    "\n",
    "\n",
    "plot_model_performance(\n",
    "        train_loss=hist.history.get('loss', []),\n",
    "        train_acc=hist.history.get('accuracy', []),\n",
    "        train_val_loss=hist.history.get('val_loss', []),\n",
    "        train_val_acc=hist.history.get('val_accuracy', [])\n",
    "    )\n",
    "score = clf.score(X_test, y_test)\n",
    "print(score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#================================================================================================#\n",
    "#========================Visulize the model======================================#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from keras.utils import plot_model\n",
    "plot_model(clf.model, to_file='model.png', show_shapes=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, classification_report, accuracy_score, confusion_matrix, f1_score\n",
    "\n",
    "def plot_confusion_matrix(f1,\n",
    "                          cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True,\n",
    "                          i=1):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}; f1-score={:0.4f}'.format(accuracy, misclass, f1))\n",
    "\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_true , y_pred)\n",
    "plot_confusion_matrix(f1_score(y_true, y_pred, average='macro'), cnf_matrix, target_names=con_tags, title='Confusion matrix', normalize=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "con_tags = {'$',',','-NONE-','JJR','NNS','SYM','TO','UH','VBD','VBN','VBZ','WP$'}\n",
    "\n",
    "tags"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_acc():\n",
    "    plt.plot(hist.history['accuracy'])\n",
    "    plt.plot(hist.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "plot_acc()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "name='model'\n",
    "print('\\n---- Result of {} ----\\n'.format(name))\n",
    "print(classification_report(y_true, y_pred, digits=4))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}