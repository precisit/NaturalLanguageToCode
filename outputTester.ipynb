{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Precisit\\Anaconda3\\envs\\NaturalLanguageToCode\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Precisit\\Anaconda3\\envs\\NaturalLanguageToCode\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Precisit\\Anaconda3\\envs\\NaturalLanguageToCode\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Precisit\\Anaconda3\\envs\\NaturalLanguageToCode\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Precisit\\Anaconda3\\envs\\NaturalLanguageToCode\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Precisit\\Anaconda3\\envs\\NaturalLanguageToCode\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Precisit\\Anaconda3\\envs\\NaturalLanguageToCode\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Precisit\\Anaconda3\\envs\\NaturalLanguageToCode\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Precisit\\Anaconda3\\envs\\NaturalLanguageToCode\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Precisit\\Anaconda3\\envs\\NaturalLanguageToCode\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Precisit\\Anaconda3\\envs\\NaturalLanguageToCode\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Precisit\\Anaconda3\\envs\\NaturalLanguageToCode\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\Precisit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\Precisit\\Anaconda3\\envs\\NaturalLanguageToCode\\lib\\site-packages\\keras\\engine\\sequential.py:111: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
      "  warnings.warn('`Sequential.model` is deprecated. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "WARNING:tensorflow:From C:\\Users\\Precisit\\Anaconda3\\envs\\NaturalLanguageToCode\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "5061/5061 [==============================] - 3s 561us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    }
   ],
   "source": [
    "from basicTrainingData import y_test, X_test, tags, prey_train, preX_train, dict_vectorizer, add_basic_features, y_train, y_val, simple_train_sentences\n",
    "from keras.models import load_model\n",
    "import re\n",
    "import pickle \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "#Deep learning model\n",
    "training_model = load_model('keras_mlp.h5')\n",
    "y_pred = training_model.model.predict(X_test, verbose=1).argmax(-1)\n",
    "y_true = y_test.argmax(-1)\n",
    "\n",
    "#Encoding model\n",
    "pkl_file = open('Departure_encoder.pkl', 'rb')\n",
    "encoder_model = pickle.load(pkl_file) \n",
    "pkl_file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Original input:  [('Without', 'IN'), ('the', 'DT'), ('Cray-3', 'NNP'), ('research', 'NN'), ('and', 'CC'), ('development', 'NN'), ('expenses', 'NNS'), (',', ','), ('the', 'DT'), ('company', 'NN'), ('would', 'MD'), ('have', 'VB'), ('been', 'VBN'), ('able', 'JJ'), ('*-2', '-NONE-'), ('to', 'TO'), ('report', 'VB'), ('a', 'DT'), ('profit', 'NN'), ('of', 'IN'), ('$', '$'), ('19.3', 'CD'), ('million', 'CD'), ('*U*', '-NONE-'), ('*ICH*-3', '-NONE-'), ('for', 'IN'), ('the', 'DT'), ('first', 'JJ'), ('half', 'DT'), ('of', 'IN'), ('1989', 'CD'), ('rather', 'RB'), ('than', 'IN'), ('the', 'DT'), ('$', '$'), ('5.9', 'CD'), ('million', 'CD'), ('*U*', '-NONE-'), ('0', '-NONE-'), ('it', 'PRP'), ('posted', 'VBD'), ('*T*-1', '-NONE-'), ('.', '.')]\n",
      "Input sentence: ['Without', 'the', 'Cray-3', 'research', 'and', 'development', 'expenses', ',', 'the', 'company', 'would', 'have', 'been', 'able', '*-2', 'to', 'report', 'a', 'profit', 'of', '$', '19.3', 'million', '*U*', '*ICH*-3', 'for', 'the', 'first', 'half', 'of', '1989', 'rather', 'than', 'the', '$', '5.9', 'million', '*U*', '0', 'it', 'posted', '*T*-1', '.']\n",
      "Decoded sentence: ['IN', 'DT', 'NNP', 'NN', 'CC', 'NN', 'NNS', ',', 'DT', 'NN', 'MD', 'VB', 'VBN', 'JJ', '-NONE-', 'TO', 'VB', 'DT', 'NN', 'IN', '$', 'CD', 'CD', '-NONE-', '-NONE-', 'IN', 'DT', 'JJ', 'DT', 'IN', 'CD', 'RB', 'IN', 'DT', '$', 'CD', 'CD', '-NONE-', '-NONE-', 'PRP', 'VBD', '-NONE-', '.']\n",
      "-\n",
      "Original input:  [('On', 'IN'), ('the', 'DT'), ('other', 'JJ'), ('hand', 'NN'), (',', ','), ('had', 'VBD'), ('it', 'PRP'), ('existed', 'VBN'), ('then', 'RB'), (',', ','), ('Cray', 'NNP'), ('Computer', 'NNP'), ('would', 'MD'), ('have', 'VB'), ('incurred', 'VBN'), ('a', 'DT'), ('$', '$'), ('20.5', 'CD'), ('million', 'CD'), ('*U*', '-NONE-'), ('loss', 'NN'), ('.', '.')]\n",
      "Input sentence: ['On', 'the', 'other', 'hand', ',', 'had', 'it', 'existed', 'then', ',', 'Cray', 'Computer', 'would', 'have', 'incurred', 'a', '$', '20.5', 'million', '*U*', 'loss', '.']\n",
      "Decoded sentence: ['IN', 'DT', 'JJ', 'NN', ',', 'VBD', 'PRP', 'VBN', 'RB', ',', 'NNP', 'NNP', 'MD', 'VB', 'VBN', 'DT', '$', 'CD', 'CD', '-NONE-', 'NN', '.']\n",
      "-\n",
      "Original input:  [('Mr.', 'NNP'), ('Cray', 'NNP'), (',', ','), ('who', 'WP'), ('*T*-1', '-NONE-'), ('could', 'MD'), (\"n't\", 'RB'), ('be', 'VB'), ('reached', 'VBN'), ('*-24', '-NONE-'), ('for', 'IN'), ('comment', 'NN'), (',', ','), ('will', 'MD'), ('work', 'VB'), ('for', 'IN'), ('the', 'DT'), ('new', 'JJ'), ('Colorado', 'NNP'), ('Springs', 'NNPS'), (',', ','), ('Colo.', 'NNP'), (',', ','), ('company', 'NN'), ('as', 'IN'), ('an', 'DT'), ('independent', 'JJ'), ('contractor', 'NN'), ('--', ':'), ('the', 'DT'), ('arrangement', 'NN'), ('0', '-NONE-'), ('he', 'PRP'), ('had', 'VBD'), ('*T*-2', '-NONE-'), ('with', 'IN'), ('Cray', 'NNP'), ('Research', 'NNP'), ('.', '.')]\n",
      "Input sentence: ['Mr.', 'Cray', ',', 'who', '*T*-1', 'could', \"n't\", 'be', 'reached', '*-24', 'for', 'comment', ',', 'will', 'work', 'for', 'the', 'new', 'Colorado', 'Springs', ',', 'Colo.', ',', 'company', 'as', 'an', 'independent', 'contractor', '--', 'the', 'arrangement', '0', 'he', 'had', '*T*-2', 'with', 'Cray', 'Research', '.']\n",
      "Decoded sentence: ['NNP', 'NNP', ',', 'WP', '-NONE-', 'MD', 'RB', 'VB', 'VBN', '-NONE-', 'IN', 'NN', ',', 'MD', 'VB', 'IN', 'DT', 'JJ', 'NNP', 'NNPS', ',', 'NNP', ',', 'NN', 'IN', 'DT', 'JJ', 'NN', ':', 'DT', 'NN', '-NONE-', 'PRP', 'VBD', '-NONE-', 'IN', 'NNP', 'NNP', '.']\n",
      "-\n",
      "Original input:  [('*-25', '-NONE-'), ('Regarded', 'VBN'), ('*-1', '-NONE-'), ('as', 'IN'), ('the', 'DT'), ('father', 'NN'), ('of', 'IN'), ('the', 'DT'), ('supercomputer', 'NN'), (',', ','), ('Mr.', 'NNP'), ('Cray', 'NNP'), ('was', 'VBD'), ('paid', 'VBN'), ('*-25', '-NONE-'), ('$', '$'), ('600,000', 'CD'), ('*U*', '-NONE-'), ('at', 'IN'), ('Cray', 'NNP'), ('Research', 'NNP'), ('last', 'JJ'), ('year', 'NN'), ('.', '.')]\n",
      "Input sentence: ['*-25', 'Regarded', '*-1', 'as', 'the', 'father', 'of', 'the', 'supercomputer', ',', 'Mr.', 'Cray', 'was', 'paid', '*-25', '$', '600,000', '*U*', 'at', 'Cray', 'Research', 'last', 'year', '.']\n",
      "Decoded sentence: ['-NONE-', 'VBN', '-NONE-', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', ',', 'NNP', 'NNP', 'VBD', 'VBN', '-NONE-', '$', 'CD', '-NONE-', 'IN', 'NNP', 'NNP', 'JJ', 'NN', '.']\n",
      "-\n",
      "Original input:  [('At', 'IN'), ('Cray', 'NNP'), ('Computer', 'NNP'), (',', ','), ('he', 'PRP'), ('will', 'MD'), ('be', 'VB'), ('paid', 'VBN'), ('*-26', '-NONE-'), ('$', '$'), ('240,000', 'CD'), ('*U*', '-NONE-'), ('.', '.')]\n",
      "Input sentence: ['At', 'Cray', 'Computer', ',', 'he', 'will', 'be', 'paid', '*-26', '$', '240,000', '*U*', '.']\n",
      "Decoded sentence: ['IN', 'NNP', 'NNP', ',', 'PRP', 'MD', 'VB', 'VBN', '-NONE-', '$', 'CD', '-NONE-', '.']\n",
      "-\n",
      "Original input:  [('Besides', 'IN'), ('Messrs.', 'NNP'), ('Cray', 'NNP'), ('and', 'CC'), ('Barnum', 'NNP'), (',', ','), ('other', 'JJ'), ('senior', 'JJ'), ('management', 'NN'), ('at', 'IN'), ('the', 'DT'), ('company', 'NN'), ('includes', 'VBZ'), ('Neil', 'NNP'), ('Davenport', 'NNP'), (',', ','), ('47', 'CD'), (',', ','), ('president', 'NN'), ('and', 'CC'), ('chief', 'NN'), ('executive', 'NN'), ('officer', 'NN'), (';', ':'), ('Joseph', 'NNP'), ('M.', 'NNP'), ('Blanchard', 'NNP'), (',', ','), ('37', 'CD'), (',', ','), ('vice', 'NN'), ('president', 'NN'), (',', ','), ('engineering', 'NN'), (';', ':'), ('Malcolm', 'NNP'), ('A.', 'NN'), ('Hammerton', 'NNP'), (',', ','), ('40', 'CD'), (',', ','), ('vice', 'NN'), ('president', 'NN'), (',', ','), ('software', 'NN'), (';', ':'), ('and', 'CC'), ('Douglas', 'NNP'), ('R.', 'NNP'), ('Wheeland', 'NNP'), (',', ','), ('45', 'CD'), (',', ','), ('vice', 'NN'), ('president', 'NN'), (',', ','), ('hardware', 'NN'), ('.', '.')]\n",
      "Input sentence: ['Besides', 'Messrs.', 'Cray', 'and', 'Barnum', ',', 'other', 'senior', 'management', 'at', 'the', 'company', 'includes', 'Neil', 'Davenport', ',', '47', ',', 'president', 'and', 'chief', 'executive', 'officer', ';', 'Joseph', 'M.', 'Blanchard', ',', '37', ',', 'vice', 'president', ',', 'engineering', ';', 'Malcolm', 'A.', 'Hammerton', ',', '40', ',', 'vice', 'president', ',', 'software', ';', 'and', 'Douglas', 'R.', 'Wheeland', ',', '45', ',', 'vice', 'president', ',', 'hardware', '.']\n",
      "Decoded sentence: ['IN', 'NNP', 'NNP', 'CC', 'NNP', ',', 'JJ', 'JJ', 'NN', 'IN', 'DT', 'NN', 'VBZ', 'NNP', 'NNP', ',', 'CD', ',', 'NN', 'CC', 'NN', 'NN', 'NN', ':', 'NNP', 'NNP', 'NNP', ',', 'CD', ',', 'NN', 'NN', ',', 'NN', ':', 'NNP', 'NN', 'NNP', ',', 'CD', ',', 'NN', 'NN', ',', 'NN', ':', 'CC', 'NNP', 'NNP', 'NNP', ',', 'CD', ',', 'NN', 'NN', ',', 'NN', '.']\n",
      "-\n",
      "Original input:  [('All', 'DT'), ('came', 'VBD'), ('from', 'IN'), ('Cray', 'NNP'), ('Research', 'NNP'), ('.', '.')]\n",
      "Input sentence: ['All', 'came', 'from', 'Cray', 'Research', '.']\n",
      "Decoded sentence: ['DT', 'VBD', 'IN', 'NNP', 'NNP', '.']\n",
      "-\n",
      "Original input:  [('Cray', 'NNP'), ('Computer', 'NNP'), (',', ','), ('which', 'WDT'), ('*T*-26', '-NONE-'), ('currently', 'RB'), ('employs', 'VBZ'), ('241', 'CD'), ('people', 'NNS'), (',', ','), ('said', 'VBD'), ('0', '-NONE-'), ('it', 'PRP'), ('expects', 'VBZ'), ('a', 'DT'), ('work', 'NN'), ('force', 'NN'), ('of', 'IN'), ('450', 'CD'), ('by', 'IN'), ('the', 'DT'), ('end', 'NN'), ('of', 'IN'), ('1990', 'CD'), ('.', '.')]\n",
      "Input sentence: ['Cray', 'Computer', ',', 'which', '*T*-26', 'currently', 'employs', '241', 'people', ',', 'said', '0', 'it', 'expects', 'a', 'work', 'force', 'of', '450', 'by', 'the', 'end', 'of', '1990', '.']\n",
      "Decoded sentence: ['NNP', 'NNP', ',', 'WDT', '-NONE-', 'RB', 'VBZ', 'CD', 'NNS', ',', 'VBD', '-NONE-', 'PRP', 'VBZ', 'DT', 'NN', 'NN', 'IN', 'CD', 'IN', 'DT', 'NN', 'IN', 'CD', '.']\n",
      "-\n",
      "Original input:  [('John', 'NNP'), ('R.', 'NNP'), ('Stevens', 'NNP'), (',', ','), ('49', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('was', 'VBD'), ('named', 'VBN'), ('*-27', '-NONE-'), ('senior', 'JJ'), ('executive', 'NN'), ('vice', 'NN'), ('president', 'NN'), ('and', 'CC'), ('chief', 'NN'), ('operating', 'VBG'), ('officer', 'NN'), (',', ','), ('both', 'DT'), ('new', 'JJ'), ('positions', 'NNS'), ('.', '.')]\n",
      "Input sentence: ['John', 'R.', 'Stevens', ',', '49', 'years', 'old', ',', 'was', 'named', '*-27', 'senior', 'executive', 'vice', 'president', 'and', 'chief', 'operating', 'officer', ',', 'both', 'new', 'positions', '.']\n",
      "Decoded sentence: ['NNP', 'NNP', 'NNP', ',', 'CD', 'NNS', 'JJ', ',', 'VBD', 'VBN', '-NONE-', 'JJ', 'NN', 'NN', 'NN', 'CC', 'NN', 'VBG', 'NN', ',', 'DT', 'JJ', 'NNS', '.']\n",
      "-\n",
      "Original input:  [('He', 'PRP'), ('will', 'MD'), ('continue', 'VB'), ('*-1', '-NONE-'), ('to', 'TO'), ('report', 'VB'), ('to', 'TO'), ('Donald', 'NNP'), ('Pardus', 'NNP'), (',', ','), ('president', 'NN'), ('and', 'CC'), ('chief', 'NN'), ('executive', 'NN'), ('officer', 'NN'), ('.', '.')]\n",
      "Input sentence: ['He', 'will', 'continue', '*-1', 'to', 'report', 'to', 'Donald', 'Pardus', ',', 'president', 'and', 'chief', 'executive', 'officer', '.']\n",
      "Decoded sentence: ['PRP', 'MD', 'VB', '-NONE-', 'TO', 'VB', 'TO', 'NNP', 'NNP', ',', 'NN', 'CC', 'NN', 'NN', 'NN', '.']\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for seq_index in range(10):\n",
    "  print('-')\n",
    "  print('Original input: ', preX_train[seq_index])\n",
    "  print('Input sentence:', simple_train_sentences[seq_index])\n",
    "  print('Decoded sentence:', prey_train[counter:counter+len(simple_train_sentences[seq_index])])\n",
    "  counter += len(simple_train_sentences[seq_index])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from collections import Counter\n",
    "\n",
    "def get_part_of_speech(word):\n",
    "  probable_part_of_speech = wordnet.synsets(word)\n",
    "  pos_counts = Counter()\n",
    "  pos_counts[\"n\"] = len(  [ item for item in probable_part_of_speech if item.pos()==\"n\"]  )\n",
    "  pos_counts[\"v\"] = len(  [ item for item in probable_part_of_speech if item.pos()==\"v\"]  )\n",
    "  pos_counts[\"a\"] = len(  [ item for item in probable_part_of_speech if item.pos()==\"a\"]  )\n",
    "  pos_counts[\"r\"] = len(  [ item for item in probable_part_of_speech if item.pos()==\"r\"]  )\n",
    "  \n",
    "  most_likely_part_of_speech = pos_counts.most_common(1)[0][0]\n",
    "  return most_likely_part_of_speech\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def clean_up_example(text):\n",
    "    cleaned = re.sub('\\W+', ' ', text)\n",
    "    tokenized = word_tokenize(cleaned)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized = [lemmatizer.lemmatize(token, get_part_of_speech(token)) for token in tokenized]\n",
    "    return lemmatized\n",
    "\n",
    "#These properties could include informations about\n",
    "# previous and next words as well as prefixes and suffixes.\n",
    "def add_basic_features(sentence_terms, index):\n",
    "    term = sentence_terms[index]\n",
    "    return {\n",
    "        'nb_terms': len(sentence_terms),\n",
    "        'term': term,\n",
    "        'is_first': index == 0,\n",
    "        'is_last': index == len(sentence_terms) - 1,\n",
    "        'is_capitalized': term[0].upper() == term[0],\n",
    "        'is_all_caps': term.upper() == term,\n",
    "        'is_all_lower': term.lower() == term,\n",
    "        'prefix-1': term[0],\n",
    "        'prefix-2': term[:2],\n",
    "        'prefix-3': term[:3],\n",
    "        'suffix-1': term[-1],\n",
    "        'suffix-2': term[-2:],\n",
    "        'suffix-3': term[-3:],\n",
    "        'prev_word': '' if index == 0 else sentence_terms[index - 1],\n",
    "        'next_word': '' if index == len(sentence_terms) - 1 else sentence_terms[index + 1]\n",
    "    }\n",
    "\n",
    "\n",
    "def give_tag(probabilities):\n",
    "    #Take out index number of most probable in each list, then decodes them    \n",
    "    maximum = probabilities.max()\n",
    "    index_of_maximum = np.where(probabilities == maximum)\n",
    "    tag = encoder_model.inverse_transform(index_of_maximum[0])\n",
    "    return tag"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input word: walk\n",
      "Decoded tag: ['VBP']\n",
      "-\n",
      "Input word: down\n",
      "Decoded tag: ['RB']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "#What to keep?\n",
    "import numpy as np\n",
    "\n",
    "example = clean_up_example(\"walk down\")\n",
    "lem_list = []\n",
    "\n",
    "for i in range(len(example)): \n",
    "    lem_list.append(add_basic_features(example, i))\n",
    "\n",
    "example_result = training_model.predict(dict_vectorizer.transform(lem_list))\n",
    "\n",
    "for i in range(len(lem_list)):\n",
    "  print('-')\n",
    "  print('Input word:', example[i])\n",
    "  print('Decoded tag:',give_tag(example_result[i]))\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}